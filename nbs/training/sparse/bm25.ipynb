{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BM25 Retrieval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is noticeable that the BM25 retrieval method is widely used in the information retrieval field. It is a ranking function used by search engines to estimate the relevance of documents to a given search query. The BM25 algorithm is based on the probabilistic information retrieval model and is a bag-of-words retrieval function that ranks a set of documents based on the query terms appearing in each document, regardless of the inter-relationship between the query terms within a document.\n",
    "\n",
    "It works significatively worse than the dense retriebal methods but it pays more attention to exact and fuzzy matches beyond semantic meaning. Fusion ranking methods can be used to combine BM25 with dense retrieval methods to improve the overall performance.\n",
    "\n",
    "For the dense retrieval, stopwords, emojis and other characters can remain with no serious affectation. However, for the BM25 retrieval, it is important to remove them to avoid noise in the retrieval process.\n",
    "\n",
    "In addition to this, as the BM25 retrieval is based on the bag-of-words model, the bigger the bag, the better the retrieval. This means that the BM25 retrieval can be improved by using the whole text of the documents instead of just the title and the body."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs/projects/bsc14/scratch/.conda/factcheck/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "from src import config\n",
    "from src.datasets import TextConcatFactCheck, TextConcatPosts\n",
    "from src.models import BM25Model\n",
    "\n",
    "tasks_path = config.TASKS_PATH\n",
    "posts_path = config.POSTS_PATH\n",
    "fact_checks_path = config.FACT_CHECKS_PATH\n",
    "gs_path = config.GS_PATH\n",
    "lang = 'deu'\n",
    "task_name = \"monolingual\"\n",
    "\n",
    "fc = TextConcatFactCheck(fact_checks_path, tasks_path=tasks_path, task_name=task_name, lang=lang, version=\"english\")\n",
    "posts = TextConcatPosts(posts_path, tasks_path=tasks_path, task_name=task_name, lang=lang, gs_path=gs_path, version=\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_posts = posts.df_train\n",
    "df_dev_posts = posts.df_dev\n",
    "df_fc = fc.df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BM25 withouth any preprocessing is used in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing texts:   0%|          | 0/61 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing texts: 100%|██████████| 61/61 [00:03<00:00, 15.92it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'monolingual': {'deu': {10: np.float64(0.4918032786885246),\n",
       "   50: np.float64(0.5245901639344263),\n",
       "   100: np.float64(0.5409836065573771)}}}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bm25_model = BM25Model(df_fc=df_fc, batch_size=512, k=100000, normalize_embeddings=True)\n",
    "df_bm25_dev = df_dev_posts.copy()\n",
    "df_bm25_dev[\"preds\"] = bm25_model.predict(df_dev_posts[\"full_text\"].values).tolist()\n",
    "bm25_model.evaluate(df_bm25_dev, task_name=task_name, lang=\"deu\", ls_k=[10, 50, 100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dense Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 10/10 [00:08<00:00,  1.16it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  1.95it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'monolingual': {'deu': {10: np.float64(0.7377049180327869),\n",
       "   50: np.float64(0.8032786885245902),\n",
       "   100: np.float64(0.8360655737704918)}}}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.models import EmbeddingModel\n",
    "teacher_model_path = '/home/bsc/bsc830651/.cache/huggingface/hub/models--intfloat--multilingual-e5-large/snapshots/ab10c1a7f42e74530fe7ae5be82e6d4f11a719eb'\n",
    "teacher_model = EmbeddingModel(model_name=teacher_model_path, df_fc=df_fc, batch_size=512, k=100000)\n",
    "df_teacher_dev = df_dev_posts.copy()\n",
    "df_teacher_dev[\"preds\"] = teacher_model.predict(df_dev_posts[\"full_text\"].values).tolist()\n",
    "teacher_model.evaluate(df_teacher_dev, task_name=task_name, lang=\"deu\", ls_k=[10, 50, 100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean and try again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "# spacy.cli.download(\"en_core_web_lg\")\n",
    "nlp = spacy.load(\"en_core_web_lg\")\n",
    "def cleaning_spacy_cased(text):\n",
    "    return \" \".join([token.lemma_ for token in nlp(text) if not token.is_stop and not token.is_punct])\n",
    "\n",
    "def cleaning_spacy(text):\n",
    "    return \" \".join([token.lemma_.lower() for token in nlp(text) if not token.is_stop and not token.is_punct])\n",
    "\n",
    "def only_entities(text):\n",
    "    return \" \".join([ent.text for ent in nlp(text).ents])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'student University Mannheim study computer science'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaning_spacy_cased(\"I am a student at the University of Mannheim and I am studying computer science.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Substantial improvement in BM25 retrieval can be achieved by cleaning the text. The cleaning process involves removing stopwords, emojis, and other characters that do not provide useful information for the retrieval process. The cleaning process can be done using the following steps:\n",
    "\n",
    "\n",
    "Cased: Worse\n",
    "\n",
    "Lowercased: Better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing texts:   0%|          | 0/61 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing texts: 100%|██████████| 61/61 [00:01<00:00, 41.62it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'monolingual': {'deu': {10: np.float64(0.639344262295082),\n",
       "   50: np.float64(0.7540983606557377),\n",
       "   100: np.float64(0.7704918032786885)}}}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "df_dev_clean = df_dev_posts.copy()\n",
    "df_fc_clean = df_fc.copy()\n",
    "\n",
    "df_dev_clean[\"full_text\"] = df_dev_clean[\"full_text\"].progress_apply(cleaning_spacy_cased)\n",
    "df_fc_clean[\"full_text\"] = df_fc_clean[\"full_text\"].progress_apply(cleaning_spacy_cased)\n",
    "\n",
    "bm25_model = BM25Model(df_fc=df_fc_clean, batch_size=512, k=100000, normalize_embeddings=True)\n",
    "df_bm25_dev = df_dev_clean.copy()\n",
    "df_bm25_dev[\"preds\"] = bm25_model.predict(df_dev_clean[\"full_text\"].values).tolist()\n",
    "bm25_model.evaluate(df_bm25_dev, task_name=task_name, lang=\"deu\", ls_k=[10, 50, 100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 61/61 [00:00<00:00, 94.45it/s] \n",
      "100%|██████████| 4996/4996 [00:29<00:00, 169.50it/s]\n",
      "Processing texts: 100%|██████████| 61/61 [00:01<00:00, 40.17it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'monolingual': {'deu': {10: np.float64(0.6557377049180327),\n",
       "   50: np.float64(0.819672131147541),\n",
       "   100: np.float64(0.819672131147541)}}}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dev_clean = df_dev_posts.copy()\n",
    "df_fc_clean = df_fc.copy()\n",
    "\n",
    "df_dev_clean[\"full_text\"] = df_dev_clean[\"full_text\"].progress_apply(cleaning_spacy)\n",
    "df_fc_clean[\"full_text\"] = df_fc_clean[\"full_text\"].progress_apply(cleaning_spacy)\n",
    "\n",
    "bm25_model = BM25Model(df_fc=df_fc_clean, batch_size=512, k=100000, normalize_embeddings=True)\n",
    "df_bm25_dev = df_dev_clean.copy()\n",
    "df_bm25_dev[\"preds\"] = bm25_model.predict(df_dev_clean[\"full_text\"].values).tolist()\n",
    "bm25_model.evaluate(df_bm25_dev, task_name=task_name, lang=\"deu\", ls_k=[10, 50, 100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, when applied to dense retrieval, the cleaning process can be detrimental to the retrieval process. This is because the dense retrieval methods are based on the semantic meaning of the text, and removing stopwords, emojis, and other characters can result in the loss of important information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 61/61 [00:00<00:00, 94.14it/s] \n",
      "100%|██████████| 4996/4996 [00:29<00:00, 171.27it/s]\n",
      "Batches: 100%|██████████| 10/10 [00:06<00:00,  1.58it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  2.20it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'monolingual': {'deu': {10: np.float64(0.6885245901639344),\n",
       "   50: np.float64(0.8032786885245902),\n",
       "   100: np.float64(0.8524590163934426)}}}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.models import EmbeddingModel\n",
    "\n",
    "df_dev_clean = df_dev_posts.copy()\n",
    "df_fc_clean = df_fc.copy()\n",
    "\n",
    "df_dev_clean[\"full_text\"] = df_dev_clean[\"full_text\"].progress_apply(cleaning_spacy_cased)\n",
    "df_fc_clean[\"full_text\"] = df_fc_clean[\"full_text\"].progress_apply(cleaning_spacy_cased)\n",
    "\n",
    "teacher_model_path = '/home/bsc/bsc830651/.cache/huggingface/hub/models--intfloat--multilingual-e5-large/snapshots/ab10c1a7f42e74530fe7ae5be82e6d4f11a719eb'\n",
    "teacher_model = EmbeddingModel(model_name=teacher_model_path, df_fc=df_fc_clean, batch_size=512, k=100000)\n",
    "df_teacher_dev = df_dev_clean.copy()\n",
    "df_teacher_dev[\"preds\"] = teacher_model.predict(df_dev_clean[\"full_text\"].values).tolist()\n",
    "teacher_model.evaluate(df_teacher_dev, task_name=task_name, lang=\"deu\", ls_k=[10, 50, 100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 61/61 [00:00<00:00, 61.86it/s] \n",
      "100%|██████████| 4996/4996 [00:30<00:00, 166.14it/s]\n",
      "Batches: 100%|██████████| 10/10 [00:06<00:00,  1.53it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  2.20it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'monolingual': {'deu': {10: np.float64(0.639344262295082),\n",
       "   50: np.float64(0.8360655737704918),\n",
       "   100: np.float64(0.8524590163934426)}}}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dev_clean = df_dev_posts.copy()\n",
    "df_fc_clean = df_fc.copy()\n",
    "\n",
    "df_dev_clean[\"full_text\"] = df_dev_clean[\"full_text\"].progress_apply(cleaning_spacy)\n",
    "df_fc_clean[\"full_text\"] = df_fc_clean[\"full_text\"].progress_apply(cleaning_spacy)\n",
    "\n",
    "teacher_model_path = '/home/bsc/bsc830651/.cache/huggingface/hub/models--intfloat--multilingual-e5-large/snapshots/ab10c1a7f42e74530fe7ae5be82e6d4f11a719eb'\n",
    "teacher_model = EmbeddingModel(model_name=teacher_model_path, df_fc=df_fc_clean, batch_size=512, k=100000)\n",
    "df_teacher_dev = df_dev_clean.copy()\n",
    "df_teacher_dev[\"preds\"] = teacher_model.predict(df_dev_clean[\"full_text\"].values).tolist()\n",
    "teacher_model.evaluate(df_teacher_dev, task_name=task_name, lang=\"deu\", ls_k=[10, 50, 100])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "factcheck",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
