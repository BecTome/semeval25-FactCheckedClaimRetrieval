{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src import config\n",
    "from src.datasets import TextConcatFactCheck, TextConcatPosts\n",
    "\n",
    "# Paths from config\n",
    "posts_path = config.POSTS_PATH\n",
    "fact_checks_path = config.FACT_CHECKS_PATH\n",
    "gs_path = config.GS_PATH\n",
    "task_path = config.TASKS_PATH\n",
    "task_name = \"monolingual\"\n",
    "lang = \"tha\"\n",
    "\n",
    "posts = TextConcatPosts(posts_path, tasks_path=task_path, gs_path=gs_path, task_name=task_name, lang=lang)\n",
    "fcs = TextConcatFactCheck(fact_checks_path, tasks_path=task_path, task_name=task_name, lang=lang)\n",
    "\n",
    "# df_posts_train = posts.df_train\n",
    "df_posts_dev = posts.df_dev\n",
    "df_fc = fcs.df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bsc/bsc830651/.conda/envs/factcheck/lib/python3.10/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py:13: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer, CrossEncoder\n",
    "import torch\n",
    "import numpy as np\n",
    "from abc import abstractmethod\n",
    "import json\n",
    "import os\n",
    "from src.models import BaseModel\n",
    "\n",
    "class CrossencoderModel(BaseModel):\n",
    "    def __init__(self, model_name, df_cands, df_fc, device=\"cuda\", show_progress_bar=True, batch_size=128, k=10, **kwargs):\n",
    "        self.model = CrossEncoder(model_name, device=device, **kwargs)\n",
    "        self.idx_to_text = df_fc[\"full_text\"].to_dict()\n",
    "        self.df_cands = df_cands.copy()\n",
    "        self.vectorized_map = np.vectorize(lambda x: self.idx_to_text.get(x, None))        \n",
    "        super().__init__(device, show_progress_bar, batch_size, k)\n",
    "\n",
    "    def train(self, texts):\n",
    "        pass\n",
    "    \n",
    "    def predict(self, post, cands_list):\n",
    "        # df_posts_dev[\"preds\"] = df_posts_dev.apply(lambda x:cross_model.predict(x[\"full_text\"], x[\"preds\"]), axis=1)\n",
    "        cands_list_text = self.vectorized_map(cands_list)\n",
    "        pos_ids = self.model.rank(post, cands_list_text, show_progress_bar=self.show_progress_bar, batch_size=self.batch_size, top_k=self.k, convert_to_numpy=True)\n",
    "        pos_ids = [pos_id[\"corpus_id\"] for pos_id in pos_ids]\n",
    "        return np.array(cands_list)[pos_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 2/2 [00:00<00:00,  4.99it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 30.47it/s]\n"
     ]
    }
   ],
   "source": [
    "from src.models import EmbeddingModel\n",
    "\n",
    "biencoder_name = \"/gpfs/projects/bsc14/abecerr1/hub/models--sentence-transformers--paraphrase-multilingual-MiniLM-L12-v2/snapshots/ae06c001a2546bef168b9bf8f570ccb1a16aaa27\"\n",
    "cand_ret_model = EmbeddingModel(biencoder_name, df_fc, show_progress_bar=True, batch_size=256, normalize_embeddings=True, k=100)\n",
    "\n",
    "df_posts_dev[\"preds\"] = cand_ret_model.predict(df_posts_dev[\"full_text\"].values).tolist()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 2.8971457, -2.334918 ]], dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cross_model = CrossencoderModel(\"amberoad/bert-multilingual-passage-reranking-msmarco\", df_posts_dev, df_fc, show_progress_bar=False, batch_size=512, k=10)\n",
    "\n",
    "cross_base = CrossEncoder(\"amberoad/bert-multilingual-passage-reranking-msmarco\", device=\"cuda\")\n",
    "cross_base.predict([(\"Hola\", \"Hallo\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "softmax = torch.nn.Softmax(dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 2.5404, -2.0186],\n",
       "        [ 2.4510, -1.9740]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(**tokenizer([\"Hola\", \"Hallo\"], return_tensors=\"pt\")).logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m cross_model \u001b[38;5;241m=\u001b[39m CrossencoderModel(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mamberoad/bert-multilingual-passage-reranking-msmarco\u001b[39m\u001b[38;5;124m\"\u001b[39m, df_posts_dev, df_fc, show_progress_bar\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m512\u001b[39m, k\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m df_posts_dev[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpreds_cross\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mdf_posts_dev\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m:\u001b[49m\u001b[43mcross_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfull_text\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpreds\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m df_posts_dev_2 \u001b[38;5;241m=\u001b[39m df_posts_dev\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m      6\u001b[0m df_posts_dev_2[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpreds\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m df_posts_dev_2[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpreds_cross\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m/gpfs/projects/bsc14/scratch/.conda/factcheck/lib/python3.10/site-packages/pandas/core/frame.py:10374\u001b[0m, in \u001b[0;36mDataFrame.apply\u001b[0;34m(self, func, axis, raw, result_type, args, by_row, engine, engine_kwargs, **kwargs)\u001b[0m\n\u001b[1;32m  10360\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapply\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m frame_apply\n\u001b[1;32m  10362\u001b[0m op \u001b[38;5;241m=\u001b[39m frame_apply(\n\u001b[1;32m  10363\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m  10364\u001b[0m     func\u001b[38;5;241m=\u001b[39mfunc,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m  10372\u001b[0m     kwargs\u001b[38;5;241m=\u001b[39mkwargs,\n\u001b[1;32m  10373\u001b[0m )\n\u001b[0;32m> 10374\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapply\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/gpfs/projects/bsc14/scratch/.conda/factcheck/lib/python3.10/site-packages/pandas/core/apply.py:916\u001b[0m, in \u001b[0;36mFrameApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw:\n\u001b[1;32m    914\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_raw(engine\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine, engine_kwargs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine_kwargs)\n\u001b[0;32m--> 916\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/gpfs/projects/bsc14/scratch/.conda/factcheck/lib/python3.10/site-packages/pandas/core/apply.py:1063\u001b[0m, in \u001b[0;36mFrameApply.apply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1061\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_standard\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m   1062\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpython\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m-> 1063\u001b[0m         results, res_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_series_generator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1064\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1065\u001b[0m         results, res_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_series_numba()\n",
      "File \u001b[0;32m/gpfs/projects/bsc14/scratch/.conda/factcheck/lib/python3.10/site-packages/pandas/core/apply.py:1081\u001b[0m, in \u001b[0;36mFrameApply.apply_series_generator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1078\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m option_context(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmode.chained_assignment\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m   1079\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(series_gen):\n\u001b[1;32m   1080\u001b[0m         \u001b[38;5;66;03m# ignore SettingWithCopy here in case the user mutates\u001b[39;00m\n\u001b[0;32m-> 1081\u001b[0m         results[i] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1082\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(results[i], ABCSeries):\n\u001b[1;32m   1083\u001b[0m             \u001b[38;5;66;03m# If we have a view on v, we need to make a copy because\u001b[39;00m\n\u001b[1;32m   1084\u001b[0m             \u001b[38;5;66;03m#  series_generator will swap out the underlying data\u001b[39;00m\n\u001b[1;32m   1085\u001b[0m             results[i] \u001b[38;5;241m=\u001b[39m results[i]\u001b[38;5;241m.\u001b[39mcopy(deep\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "Cell \u001b[0;32mIn[4], line 3\u001b[0m, in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m      1\u001b[0m cross_model \u001b[38;5;241m=\u001b[39m CrossencoderModel(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mamberoad/bert-multilingual-passage-reranking-msmarco\u001b[39m\u001b[38;5;124m\"\u001b[39m, df_posts_dev, df_fc, show_progress_bar\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m512\u001b[39m, k\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m df_posts_dev[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpreds_cross\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m df_posts_dev\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x:\u001b[43mcross_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfull_text\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpreds\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m      5\u001b[0m df_posts_dev_2 \u001b[38;5;241m=\u001b[39m df_posts_dev\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m      6\u001b[0m df_posts_dev_2[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpreds\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m df_posts_dev_2[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpreds_cross\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "Cell \u001b[0;32mIn[2], line 30\u001b[0m, in \u001b[0;36mCrossencoderModel.predict\u001b[0;34m(self, post, cands_list)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, post, cands_list):\n\u001b[1;32m     29\u001b[0m     cands_list_text \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvectorized_map(cands_list)\n\u001b[0;32m---> 30\u001b[0m     pos_ids \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrank\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpost\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcands_list_text\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_k\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert_to_numpy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     31\u001b[0m     pos_ids \u001b[38;5;241m=\u001b[39m [pos_id[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcorpus_id\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m pos_id \u001b[38;5;129;01min\u001b[39;00m pos_ids]\n\u001b[1;32m     32\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray(cands_list)[pos_ids]\n",
      "File \u001b[0;32m/gpfs/projects/bsc14/scratch/.conda/factcheck/lib/python3.10/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py:552\u001b[0m, in \u001b[0;36mCrossEncoder.rank\u001b[0;34m(self, query, documents, top_k, return_documents, batch_size, show_progress_bar, num_workers, activation_fct, apply_softmax, convert_to_numpy, convert_to_tensor)\u001b[0m\n\u001b[1;32m    549\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    550\u001b[0m         results\u001b[38;5;241m.\u001b[39mappend({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcorpus_id\u001b[39m\u001b[38;5;124m\"\u001b[39m: i, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscore\u001b[39m\u001b[38;5;124m\"\u001b[39m: scores[i]})\n\u001b[0;32m--> 552\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msorted\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mresults\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mscore\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreverse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    553\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m results[:top_k]\n",
      "\u001b[0;31mValueError\u001b[0m: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()"
     ]
    }
   ],
   "source": [
    "cross_model = CrossencoderModel(\"amberoad/bert-multilingual-passage-reranking-msmarco\", df_posts_dev, df_fc, show_progress_bar=False, batch_size=512, k=10)\n",
    "\n",
    "df_posts_dev[\"preds_cross\"] = df_posts_dev.apply(lambda x:cross_model.predict(x[\"full_text\"], x[\"preds\"]), axis=1)\n",
    "\n",
    "df_posts_dev_2 = df_posts_dev.copy()\n",
    "df_posts_dev_2[\"preds\"] = df_posts_dev_2[\"preds_cross\"]\n",
    "\n",
    "cross_model.evaluate(df_posts_dev_2, task_name=task_name, lang=lang)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'monolingual': {'fra': {1: np.float64(0.46405228758169936),\n",
       "   3: np.float64(0.6013071895424836),\n",
       "   5: np.float64(0.6470588235294118),\n",
       "   10: np.float64(0.6993464052287581)}}}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_model.evaluate(df_posts_dev_2, task_name=\"monolingual\", lang=\"fra\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{15: 'whatsapp : une vidéo « martinelli » qui va contaminer votre téléphone ? aucune preuve en ce sens \" il y a une vidéo qui sera lancée demain à whatsapp et qui s’appelle martinelli. \"',\n",
       " 136: 'fatou sarr sow se trompe sur le taux d’alphabétisation des femmes au sénégal \"1960 on n’était que 3% des femmes alphabétisées. si on regarde aujourd’hui on n’est pas satisfait parce qu’on a 46-47%\"',\n",
       " 155: 'est-il vrai que 25% des effets secondaires des vaccins contre le covid sont «graves» ? \"25% des effets secondaires liés aux vaccins sont graves\"',\n",
       " 156: 'non, les autorités congolaises n’ont pas enregistré la reddition de \"26 groupes armés\" dans l’est de la rdc \"26 groupes armés\" ont rendu les armes dans la province de l\\'ituri en république démocratique du congo',\n",
       " 187: 'sénégal : 5 % des élèves consomment-ils de la drogue ? \"5 % des élèves consomment de la drogue\".',\n",
       " 214: '\"80% des blancs sont tués par des noirs\" aux etats-unis, selon zemmour. c\\'est cinq fois moins \"80% des blancs sont tués par des noirs\" aux etats-unis, selon eric zemmour',\n",
       " 584: 'oui ambulance nouveau-brunswick a manqué à ses obligations tel que prévu par la loi sur les langues officielles \"ambulance nb a manqué à ses obligations linguistiques lors d\\'un appel d\\'urgence.\"',\n",
       " 1187: 'désinfox les écologistes sont-ils derrière toutes les pistes cyclables ? \"ce sont les élus écologistes qui, dans toutes les villes, développent les pistes cyclables\"',\n",
       " 1193: 'utilisation fallacieuse d’une photo datant de juin 2020 pour illustrer une rumeur \"ces\" policiers ne pouvaient rien faire contre la ruse d\\'un cafetier aux pays-bas qui a vendu ses chaises 5 euros à des clients (avec une bière dessus)',\n",
       " 1231: '\"christophe\", \"gilet jaune\" et \"nationaliste\" radical blessé au visage à paris par un tir de lbd ? ce que l\\'on sait \"christophe\", gilet jaune, blessé au visage par un tir de lbd ?'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_fc.iloc[:10][\"full_text\"].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_to_text = df_fc[\"full_text\"].to_dict()\n",
    "\n",
    "fun = np.vectorize(lambda x: idx_to_text.get(x, None))\n",
    "\n",
    "df_posts_dev[\"preds_text\"] = df_posts_dev[\"preds\"].apply(fun)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ce_model = CrossEncoder(\"cross-encoder/stsb-distilroberta-base\", device=\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "post_id\n",
       "291      [{'corpus_id': 0, 'score': 0.81704694}, {'corp...\n",
       "675      [{'corpus_id': 73, 'score': 0.61601925}, {'cor...\n",
       "1073     [{'corpus_id': 88, 'score': 0.49774748}, {'cor...\n",
       "1292     [{'corpus_id': 36, 'score': 0.5635742}, {'corp...\n",
       "1299     [{'corpus_id': 68, 'score': 0.6377366}, {'corp...\n",
       "                               ...                        \n",
       "27843    [{'corpus_id': 93, 'score': 0.8546004}, {'corp...\n",
       "27856    [{'corpus_id': 75, 'score': 0.63924944}, {'cor...\n",
       "27882    [{'corpus_id': 0, 'score': 0.5952376}, {'corpu...\n",
       "27896    [{'corpus_id': 2, 'score': 0.589157}, {'corpus...\n",
       "27897    [{'corpus_id': 13, 'score': 0.5853241}, {'corp...\n",
       "Length: 153, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "sigmoid = torch.nn.Sigmoid()\n",
    "scores = df_posts_dev.apply(lambda x: ce_model.rank(x[\"full_text\"], x[\"preds_text\"], top_k=10, convert_to_numpy=True), axis=1)\n",
    "# model = CrossEncoder('model_name', max_length=512)\n",
    "# scores = model.predict([('Query', 'Paragraph1'), ('Query', 'Paragraph2') , ('Query', 'Paragraph3')])\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_preds = scores.map(lambda x: [i[\"corpus_id\"] for i in x])\n",
    "df_posts_dev[\"pos_preds\"] = pos_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "post_id\n",
       "291      [10453, 82708, 79322, 155790, 11378, 80408, 15...\n",
       "675      [36592, 83261, 80178, 27977, 27772, 147115, 44...\n",
       "1073     [22026, 28270, 137418, 36663, 44372, 82576, 82...\n",
       "1292     [23311, 78538, 136865, 138187, 61810, 61671, 5...\n",
       "1299     [27774, 22026, 61671, 138129, 3284, 83546, 522...\n",
       "                               ...                        \n",
       "27843    [92820, 137024, 36592, 150822, 79482, 150823, ...\n",
       "27856    [74919, 27774, 9319, 40405, 138113, 36548, 831...\n",
       "27882    [82722, 36660, 92696, 87120, 81432, 52283, 400...\n",
       "27896    [22026, 155810, 44367, 92820, 156184, 36660, 7...\n",
       "27897    [44252, 36550, 138129, 137990, 3284, 36553, 11...\n",
       "Length: 153, dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_posts_dev.apply(lambda x: np.array(x[\"preds\"])[np.array(x[\"pos_preds\"])], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "530 millions d'euros pour des ordinateurs dans les prisons et seulement 70 millions d'euros pour les hôpitaux..! C'est quoi le problème de ce pays..? \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['\"530 millions pour des ordi dans les prisons, seulement 70 pour les hôpitaux\" : pourquoi ce visuel est trompeur 530 millions d\\'euros pour des ordinateurs dans les prisons et seulement 70 millions d\\'euros pour les hôpitaux',\n",
       "       '\"en douze mois, 39.000 retraités pauvres supplémentaires\" en france ? ce chiffre date de 2013 le nombre de retraités pauvres a augmenté de 39.000 personnes sur les douze derniers mois',\n",
       "       \"70 milliards d'euros reversés à l'etat au titre des taxes sur les carburants ? un chiffre très surestimé l'etat touche 70 milliards d'euros grâce aux taxes sur le carburant\",\n",
       "       'video. la télévision « gratuite » en prison et « payante » dans les hôpitaux ? retour sur une intox « la télévision est payante dans les hôpitaux et gratuite dans les prisons »',\n",
       "       \"smic : une personne à temps complet perçoit-elle 1.450 euros ? pourquoi la déclaration d'elisabeth borne n'est pas juste – de facto – des clés pour mieux s'informer = smic : une personne à temps complet perçoit 1.450 euros =\",\n",
       "       'burkina faso : l’internet haut-débit coûte-il 536 000 francs par mois ? la connexion internet haut-début coûte en moyenne 536.000 francs cfa au burkina faso.',\n",
       "       \"hôpitaux de paris: l'arabie saoudite qui doit 3,7 millions d'euros à l'ap-hp? pourquoi ce montant n'est plus valable «le roi d’arabie saoudite doit 3,7 millions d’euros aux hôpitaux de paris et ne payera pas»\",\n",
       "       'oui, le sénégal est parmi les 5 pays africains à « risque faible de surendettement » « sur les 55 pays de l’union africaine, le sénégal fait partie des 5 pays à risque de surendettement faible. et parmi les pays membres de la cedeao, le seul à risque de surendettement faible ».',\n",
       "       \"des détenus libérés parce qu'ils se plaignent de leurs conditions d'incarcération ? attention, c'est trompeur des prisonniers libérés parce qu'ils se plaignent de leurs conditions de détention\",\n",
       "       '90 % des maires du sénégal ont-ils des indemnités mensuelles de moins de 300 000 francs cfa ? (actualisé) 90 % des maires du pays ont un salaire de moins de 300 000 francs cfa.'],\n",
       "      dtype='<U686')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df_posts_dev[\"full_text\"].iloc[0])\n",
    "idxs = df_posts_dev[\"pos_preds\"].iloc[0]\n",
    "df_posts_dev[\"preds_text\"].iloc[0][idxs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Le personnel qui travaille à l'hôpital souhaite que ce message soit diffusé à tous !!! ATTENTION ATTENTION A À partir de demain, ne quittez pas la maison et pour le pain, si vous pouvez congeler car le pire commence: la date d'incubation est respectée et de nombreux positifs vont commencer à sortir et beaucoup de gens peuvent le contracter ! il est donc très important de rester à la maison et ne pas interagir avec personne. Du 23 mars au 3 avril nous devons prendre soin de nous car nous serons au sommet du virus; la période d'incubation est de deux semaines, normalement durant ces deux semaines tous les infectés se déclarent, puis il y a deux semaines de calme et puis deux semaines où ils diminuent. NOUS SERONS EN STADE D'INFECTION MAXIMALE. Veuillez transmettre ce message à tous vos contacts. Le personnel qui travaille à l'hôpital souhaite que ce message soit diffusé à tous; #RESTEZCHEZVOUS Le personnel hospitalier souhaite que ce message soit diffusé à TOUS\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['un calendrier prouvant que la livraison des vaccins pfizer est suspendue pendant la campagne présidentielle ? une \"erreur de saisie\", selon la dgs un calendrier prouve que la livraison des vaccins pfizer est suspendue',\n",
       "       '\"en stade d\\'infection maximale\" : ce message contient des informations infondées un pic épidémique à partir du 23 mars',\n",
       "       \"attention à ce message sur la période d’incubation de la covid-19 | coronavirus il faudrait éviter de sortir de chez soi jusqu'au 3 avril, car on atteint un « stade d'infection maximale »\",\n",
       "       'cristiano ronaldo et un hôpital au chili : une intox massivement reprise cristiano ronaldo a-t-il annoncé vouloir construire un hôpital pédiatrique au chili ?',\n",
       "       \"le pass sanitaire est-il nécessaire à l’hôpital en cas d’urgence ? c’est faux le pass sanitaire est nécessaire pour entrer à l'hôpital en cas d'urgence\",\n",
       "       \"“pas d’aiguille” lors de la vaccination de kamala harris contre le covid-19 ? pas si vite... il n'y a pas d'aiguille lors de la vaccination de kamala harris\",\n",
       "       'covid-19 : est-il vrai que 80 % des hospitalisations concernent des non-vaccinés, comme le dit karine lacombe ? – libération l\\'infectiologue karine lacombe assure que \"80% des personnes hospitalisées pour covid-19 ne sont pas vaccinées\".',\n",
       "       \"« touche pas à mon poste » déprogrammée ? cyril hanouna dément « scoop - l'émission de lien : cyril hanouna (touche pas à mon poste) devrait être déprogrammée définitivement de la chaîne c8 dans les prochaines semaines selon une source interne au csa. cette décision fait suite aux propos polémiques de\",\n",
       "       'des vaccins anti-covid qui n\\'empêchent pas de contracter le virus, une \"première dans l\\'histoire\" ? attention à cette infox c\\'est la première fois qu\\'un vaccin n\\'empêche pas l\\'infection par un virus',\n",
       "       'une \"explosion\" de l\\'épidémie de covid-19 prévue en février ? les affirmations contestées d\\'emmanuel macron des projections tablaient sur une \"explosion\" de l\\'épidémie de covid-19 en février'],\n",
       "      dtype='<U842')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df_posts_dev[\"full_text\"].iloc[10])\n",
    "idxs = df_posts_dev[\"pos_preds\"].iloc[10]\n",
    "df_posts_dev[\"preds_text\"].iloc[10][idxs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['\"530 millions pour des ordi dans les prisons, seulement 70 pour les hôpitaux\" : pourquoi ce visuel est trompeur 530 millions d\\'euros pour des ordinateurs dans les prisons et seulement 70 millions d\\'euros pour les hôpitaux',\n",
       "       '\"en douze mois, 39.000 retraités pauvres supplémentaires\" en france ? ce chiffre date de 2013 le nombre de retraités pauvres a augmenté de 39.000 personnes sur les douze derniers mois',\n",
       "       \"70 milliards d'euros reversés à l'etat au titre des taxes sur les carburants ? un chiffre très surestimé l'etat touche 70 milliards d'euros grâce aux taxes sur le carburant\",\n",
       "       'video. la télévision « gratuite » en prison et « payante » dans les hôpitaux ? retour sur une intox « la télévision est payante dans les hôpitaux et gratuite dans les prisons »',\n",
       "       \"smic : une personne à temps complet perçoit-elle 1.450 euros ? pourquoi la déclaration d'elisabeth borne n'est pas juste – de facto – des clés pour mieux s'informer = smic : une personne à temps complet perçoit 1.450 euros =\",\n",
       "       'burkina faso : l’internet haut-débit coûte-il 536 000 francs par mois ? la connexion internet haut-début coûte en moyenne 536.000 francs cfa au burkina faso.',\n",
       "       \"hôpitaux de paris: l'arabie saoudite qui doit 3,7 millions d'euros à l'ap-hp? pourquoi ce montant n'est plus valable «le roi d’arabie saoudite doit 3,7 millions d’euros aux hôpitaux de paris et ne payera pas»\",\n",
       "       'oui, le sénégal est parmi les 5 pays africains à « risque faible de surendettement » « sur les 55 pays de l’union africaine, le sénégal fait partie des 5 pays à risque de surendettement faible. et parmi les pays membres de la cedeao, le seul à risque de surendettement faible ».',\n",
       "       \"des détenus libérés parce qu'ils se plaignent de leurs conditions d'incarcération ? attention, c'est trompeur des prisonniers libérés parce qu'ils se plaignent de leurs conditions de détention\",\n",
       "       '90 % des maires du sénégal ont-ils des indemnités mensuelles de moins de 300 000 francs cfa ? (actualisé) 90 % des maires du pays ont un salaire de moins de 300 000 francs cfa.'],\n",
       "      dtype='<U686')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idxs = df_posts_dev[\"pos_preds\"].iloc[0]\n",
    "df_posts_dev[\"preds_text\"].iloc[0][idxs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: A man is eating pasta.\n",
      "0.67\tA man is eating food.\n",
      "0.34\tA man is eating a piece of bread.\n",
      "0.08\tA man is riding a horse.\n",
      "0.07\tA man is riding a white horse on an enclosed ground.\n",
      "0.01\tThe girl is carrying a baby.\n",
      "0.01\tTwo men pushed carts through the woods.\n",
      "0.01\tA monkey is playing drums.\n",
      "0.01\tA woman is playing violin.\n",
      "0.01\tA cheetah is running behind its prey.\n",
      "scores: [0.67323714 0.34102535 0.00542465 0.07569339 0.00525378 0.00536814\n",
      " 0.06676241 0.00534824 0.00516718]\n",
      "indices: [0 1 3 6 2 5 7 4 8]\n"
     ]
    }
   ],
   "source": [
    "model = CrossEncoder(\"cross-encoder/stsb-distilroberta-base\")\n",
    "\n",
    "\n",
    "# We want to compute the similarity between the query sentence\n",
    "query = \"A man is eating pasta.\"\n",
    "\n",
    "# With all sentences in the corpus\n",
    "corpus = [\n",
    "    \"A man is eating food.\",\n",
    "    \"A man is eating a piece of bread.\",\n",
    "    \"The girl is carrying a baby.\",\n",
    "    \"A man is riding a horse.\",\n",
    "    \"A woman is playing violin.\",\n",
    "    \"Two men pushed carts through the woods.\",\n",
    "    \"A man is riding a white horse on an enclosed ground.\",\n",
    "    \"A monkey is playing drums.\",\n",
    "    \"A cheetah is running behind its prey.\",\n",
    "]\n",
    "\n",
    "# 1. We rank all sentences in the corpus for the query\n",
    "ranks = model.rank(query, corpus)\n",
    "\n",
    "# Print the scores\n",
    "print(\"Query:\", query)\n",
    "for rank in ranks:\n",
    "    print(f\"{rank['score']:.2f}\\t{corpus[rank['corpus_id']]}\")\n",
    "\n",
    "# 2. Alternatively, you can also manually compute the score between two sentences\n",
    "sentence_combinations = [[query, sentence] for sentence in corpus]\n",
    "scores = model.predict(sentence_combinations)\n",
    "\n",
    "# Sort the scores in decreasing order to get the corpus indices\n",
    "ranked_indices = np.argsort(scores)[::-1]\n",
    "print(\"scores:\", scores)\n",
    "print(\"indices:\", ranked_indices)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "factcheck",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
