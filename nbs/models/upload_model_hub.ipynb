{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a91848c002fb49979af0b1fa509dd1a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token has not been saved to git credential helper.\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec3fd5f79f0e41e49d080a44229e1205",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/557M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e51ea169cd742e89450800612210c91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/5.17k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No files have been modified since last commit. Skipping to prevent empty commit.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/UPC-HLE/example10/commit/3db71c8a13746823efeff14aa43cbe945d184e6a', commit_message='Upload config', commit_description='', oid='3db71c8a13746823efeff14aa43cbe945d184e6a', pr_url=None, repo_url=RepoUrl('https://huggingface.co/UPC-HLE/example10', endpoint='https://huggingface.co', repo_type='model', repo_id='UPC-HLE/example10'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from transformers import AutoConfig, AutoModelForSequenceClassification\n",
    "local_model_path = \"output/official/contrastive/monolingual/20241102-171126/monolingual_eng_reranker\"\n",
    "hf_model_name = \"UPC-HLE/example10\"\n",
    "\n",
    "# model_st = SentenceTransformer(model_name_or_path=local_model_path, trust_remote_code=True)\n",
    "# model_st.push_to_hub(hf_model_name, private=True, exist_ok=True)\n",
    "\n",
    "# model_st= SentenceTransformer(model_name_or_path=local_model_path, trust_remote_code=True)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    local_model_path,\n",
    "    torch_dtype=\"auto\",\n",
    "    trust_remote_code=True,\n",
    ").to('cuda').eval()\n",
    "\n",
    "config = AutoConfig.from_pretrained(\n",
    "    local_model_path,\n",
    "    trust_remote_code=True,\n",
    ")\n",
    "\n",
    "model.push_to_hub(hf_model_name, private=True, exist_ok=True)\n",
    "config.push_to_hub(hf_model_name, private=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'transformers.jinaai'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mxlm_roberta\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconfiguration_xlm_roberta\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m XLMRobertaConfig\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AutoModel\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mjinaai\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mjina_reranker_v2_base_multilingual\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconfiguration_xlm_roberta\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m XLMRobertaFlashConfig\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# configuration_xlm_roberta.XLMRobertaFlashConfig\u001b[39;00m\n\u001b[1;32m      5\u001b[0m config \u001b[38;5;241m=\u001b[39m XLMRobertaConfig\u001b[38;5;241m.\u001b[39mfrom_pretrained(hf_model_name, trust_remote_code\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'transformers.jinaai'"
     ]
    }
   ],
   "source": [
    "from transformers.models.xlm_roberta.configuration_xlm_roberta import XLMRobertaConfig\n",
    "from transformers import AutoModel\n",
    "# from transformers.jinaai.jina_reranker_v2_base_multilingual.configuration_xlm_roberta import XLMRobertaFlashConfig\n",
    "# configuration_xlm_roberta.XLMRobertaFlashConfig\n",
    "config = XLMRobertaConfig.from_pretrained(hf_model_name, trust_remote_code=True)\n",
    "model = AutoModel.from_pretrained(hf_model_name, trust_remote_code=True, config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The model class you are passing has a `config_class` attribute that is not consistent with the config class you passed (model has <class 'transformers_modules.jinaai.jina-reranker-v2-base-multilingual.126747772a932960028d9f4dc93bd5d9c4869be4.configuration_xlm_roberta.XLMRobertaFlashConfig'> and you passed <class 'transformers_modules.UPC-HLE.example10.3db71c8a13746823efeff14aa43cbe945d184e6a.configuration_xlm_roberta.XLMRobertaFlashConfig'>. Fix one of those so they match!",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msentence_transformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CrossEncoder\n\u001b[0;32m----> 3\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mCrossEncoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhf_model_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mautomodel_args\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtorch_dtype\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mauto\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Example query and documents\u001b[39;00m\n\u001b[1;32m     10\u001b[0m query \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOrganic skincare products for sensitive skin\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m/gpfs/projects/bsc14/scratch/.conda/factcheck/lib/python3.10/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py:104\u001b[0m, in \u001b[0;36mCrossEncoder.__init__\u001b[0;34m(self, model_name, num_labels, max_length, device, automodel_args, tokenizer_args, config_args, cache_dir, trust_remote_code, revision, local_files_only, default_activation_function, classifier_dropout)\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m num_labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    103\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mnum_labels \u001b[38;5;241m=\u001b[39m num_labels\n\u001b[0;32m--> 104\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m \u001b[43mAutoModelForSequenceClassification\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    105\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    106\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    107\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    108\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrust_remote_code\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    109\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    110\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    111\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mautomodel_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    112\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtokenizer \u001b[38;5;241m=\u001b[39m AutoTokenizer\u001b[38;5;241m.\u001b[39mfrom_pretrained(\n\u001b[1;32m    114\u001b[0m     model_name,\n\u001b[1;32m    115\u001b[0m     revision\u001b[38;5;241m=\u001b[39mrevision,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    119\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mtokenizer_args,\n\u001b[1;32m    120\u001b[0m )\n\u001b[1;32m    121\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_length \u001b[38;5;241m=\u001b[39m max_length\n",
      "File \u001b[0;32m/gpfs/projects/bsc14/scratch/.conda/factcheck/lib/python3.10/site-packages/transformers/models/auto/auto_factory.py:557\u001b[0m, in \u001b[0;36m_BaseAutoModelClass.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    553\u001b[0m model_class \u001b[38;5;241m=\u001b[39m get_class_from_dynamic_module(\n\u001b[1;32m    554\u001b[0m     class_ref, pretrained_model_name_or_path, code_revision\u001b[38;5;241m=\u001b[39mcode_revision, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mhub_kwargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m    555\u001b[0m )\n\u001b[1;32m    556\u001b[0m _ \u001b[38;5;241m=\u001b[39m hub_kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcode_revision\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m--> 557\u001b[0m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mregister\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__class__\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_class\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexist_ok\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    558\u001b[0m model_class \u001b[38;5;241m=\u001b[39m add_generation_mixin_to_remote_model(model_class)\n\u001b[1;32m    559\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m model_class\u001b[38;5;241m.\u001b[39mfrom_pretrained(\n\u001b[1;32m    560\u001b[0m     pretrained_model_name_or_path, \u001b[38;5;241m*\u001b[39mmodel_args, config\u001b[38;5;241m=\u001b[39mconfig, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mhub_kwargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m    561\u001b[0m )\n",
      "File \u001b[0;32m/gpfs/projects/bsc14/scratch/.conda/factcheck/lib/python3.10/site-packages/transformers/models/auto/auto_factory.py:584\u001b[0m, in \u001b[0;36m_BaseAutoModelClass.register\u001b[0;34m(cls, config_class, model_class, exist_ok)\u001b[0m\n\u001b[1;32m    574\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    575\u001b[0m \u001b[38;5;124;03mRegister a new model for this class.\u001b[39;00m\n\u001b[1;32m    576\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    581\u001b[0m \u001b[38;5;124;03m        The model to register.\u001b[39;00m\n\u001b[1;32m    582\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    583\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(model_class, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconfig_class\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(model_class\u001b[38;5;241m.\u001b[39mconfig_class) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mstr\u001b[39m(config_class):\n\u001b[0;32m--> 584\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    585\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe model class you are passing has a `config_class` attribute that is not consistent with the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    586\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconfig class you passed (model has \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_class\u001b[38;5;241m.\u001b[39mconfig_class\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and you passed \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig_class\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. Fix \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    587\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mone of those so they match!\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    588\u001b[0m     )\n\u001b[1;32m    589\u001b[0m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mregister(config_class, model_class, exist_ok\u001b[38;5;241m=\u001b[39mexist_ok)\n",
      "\u001b[0;31mValueError\u001b[0m: The model class you are passing has a `config_class` attribute that is not consistent with the config class you passed (model has <class 'transformers_modules.jinaai.jina-reranker-v2-base-multilingual.126747772a932960028d9f4dc93bd5d9c4869be4.configuration_xlm_roberta.XLMRobertaFlashConfig'> and you passed <class 'transformers_modules.UPC-HLE.example10.3db71c8a13746823efeff14aa43cbe945d184e6a.configuration_xlm_roberta.XLMRobertaFlashConfig'>. Fix one of those so they match!"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import CrossEncoder\n",
    "\n",
    "model = CrossEncoder(\n",
    "    hf_model_name,\n",
    "    automodel_args={\"torch_dtype\": \"auto\"},\n",
    "    trust_remote_code=True,\n",
    ")\n",
    "\n",
    "# Example query and documents\n",
    "query = \"Organic skincare products for sensitive skin\"\n",
    "documents = [\n",
    "    \"Organic skincare for sensitive skin with aloe vera and chamomile.\",\n",
    "    \"New makeup trends focus on bold colors and innovative techniques\",\n",
    "    \"Bio-Hautpflege für empfindliche Haut mit Aloe Vera und Kamille\",\n",
    "    \"Neue Make-up-Trends setzen auf kräftige Farben und innovative Techniken\",\n",
    "    \"Cuidado de la piel orgánico para piel sensible con aloe vera y manzanilla\",\n",
    "    \"Las nuevas tendencias de maquillaje se centran en colores vivos y técnicas innovadoras\",\n",
    "    \"针对敏感肌专门设计的天然有机护肤产品\",\n",
    "    \"新的化妆趋势注重鲜艳的颜色和创新的技巧\",\n",
    "    \"敏感肌のために特別に設計された天然有機スキンケア製品\",\n",
    "    \"新しいメイクのトレンドは鮮やかな色と革新的な技術に焦点を当てています\",\n",
    "]\n",
    "\n",
    "# construct sentence pairs\n",
    "sentence_pairs = [[query, doc] for doc in documents]\n",
    "\n",
    "scores = model.predict(sentence_pairs, convert_to_tensor=True).tolist()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No sentence-transformers model found with name output/official/contrastive/monolingual/20241102-171126/monolingual_eng_reranker. Creating a new one with mean pooling.\n",
      "Some weights of XLMRobertaModel were not initialized from the model checkpoint at output/official/contrastive/monolingual/20241102-171126/monolingual_eng_reranker and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0.9937]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_st2 = SentenceTransformer(model_name_or_path=local_model_path, trust_remote_code=True)\n",
    "emb1 = model_st2.encode('hello')\n",
    "emb2 = model_st2.encode('world')\n",
    "model_st2.similarity(emb1, emb2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "cos_sim() takes 2 positional arguments but 3 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 18\u001b[0m\n\u001b[1;32m     15\u001b[0m candidates \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthe car goes fast\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthe car goes slow\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthe bicycle goes slow\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     16\u001b[0m sentence_pairs \u001b[38;5;241m=\u001b[39m [[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthe car drives fast\u001b[39m\u001b[38;5;124m\"\u001b[39m, doc] \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m candidates]\n\u001b[0;32m---> 18\u001b[0m scores \u001b[38;5;241m=\u001b[39m \u001b[43mmodel_st2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msimilarity\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msentence_pairs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28mprint\u001b[39m(scores)\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# model.push_to_hub(\"UPC-HLE/example2\", private=True, exist_ok=True)\u001b[39;00m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# config.push_to_hub(\"UPC-HLE/example2\", private=True, exist_ok=True)\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: cos_sim() takes 2 positional arguments but 3 were given"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification, AutoConfig\n",
    "\n",
    "# hf_model_name = \n",
    "# model = AutoModelForSequenceClassification.from_pretrained(\n",
    "#     model_name_or_path,\n",
    "#     torch_dtype=\"auto\",\n",
    "#     trust_remote_code=True,\n",
    "# ).to('cuda').eval()\n",
    "\n",
    "# config = AutoConfig.from_pretrained(\n",
    "#     model_name_or_path,\n",
    "#     trust_remote_code=True,\n",
    "# )\n",
    "\n",
    "candidates = [\"the car goes fast\", \"the car goes slow\", \"the bicycle goes slow\"]\n",
    "sentence_pairs = [[\"the car drives fast\", doc] for doc in candidates]\n",
    "\n",
    "scores = model.compute_score(sentence_pairs, max_length=1024)\n",
    "print(scores)\n",
    "\n",
    "# model.push_to_hub(\"UPC-HLE/example2\", private=True, exist_ok=True)\n",
    "# config.push_to_hub(\"UPC-HLE/example2\", private=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers.model_card import SentenceTransformerModelCardData\n",
    "card = SentenceTransformerModelCardData(base_model="
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "factcheck",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
